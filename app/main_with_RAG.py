from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import os
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
import json
import re
import asyncio
import logging
from logging.handlers import RotatingFileHandler

# RAG ë²¡í„° DB ê´€ë ¨ import
try:
    from langchain_community.vectorstores import FAISS
    from langchain_google_genai import GoogleGenerativeAIEmbeddings

    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    FAISS = None
    GoogleGenerativeAIEmbeddings = None

# OpenAI ì„ë² ë”© ì§€ì› ì¶”ê°€
try:
    from langchain_openai import OpenAIEmbeddings

    OPENAI_EMBEDDINGS_AVAILABLE = True
except ImportError:
    OPENAI_EMBEDDINGS_AVAILABLE = False
    OpenAIEmbeddings = None

load_dotenv()

# ë¡œê¹… ì„¤ì •
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
LOG_DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("pop_pins_api")
logger.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))
console_formatter = logging.Formatter(LOG_FORMAT, datefmt=LOG_DATE_FORMAT)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ (ì„ íƒì‚¬í•­ - logs ë””ë ‰í† ë¦¬ì— ì €ì¥)
logs_dir = Path(__file__).parent.parent / "logs"
logs_dir.mkdir(exist_ok=True)
log_file = logs_dir / "app.log"

file_handler = RotatingFileHandler(
    log_file,
    maxBytes=10 * 1024 * 1024,  # 10MB
    backupCount=5,
    encoding="utf-8"
)
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter(LOG_FORMAT, datefmt=LOG_DATE_FORMAT)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)

logger.info("ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

app = FastAPI(title="ììŠµ ê³¼ì œ ìƒì„± API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY or GEMINI_API_KEY == "your_api_key_here":
    raise ValueError(
        "GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
        ".env íŒŒì¼ì„ ì—´ì–´ì„œ ì‹¤ì œ Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n"
        "API í‚¤ëŠ” https://makersuite.google.com/app/apikey ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

genai.configure(api_key=GEMINI_API_KEY)
# Gemini ëª¨ë¸: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp ë“± ì‚¬ìš© ê°€ëŠ¥
# ì‚¬ìš©ìê°€ ìš”ì²­í•œ 2.5 flashëŠ” ì•„ì§ ê³µì‹ì ìœ¼ë¡œ ì—†ìœ¼ë¯€ë¡œ 2.0-flash-exp ë˜ëŠ” 1.5-flash ì‚¬ìš©
model = genai.GenerativeModel("gemini-2.5-flash")  # ë˜ëŠ” 'gemini-2.0-flash-exp'

# RAG ë²¡í„° DB ì„¤ì •
VECTOR_DB_PATH = os.getenv(
    "VECTOR_DB_PATH",
    str(Path(__file__).parent.parent / "python_textbook_gemini_db_semantic"),
)
VECTOR_DB_EMBEDDING_MODEL = os.getenv(
    "VECTOR_DB_EMBEDDING_MODEL", "gemini"
)  # ë²¡í„° DB ìƒì„± ì‹œ ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸
USE_RAG = os.getenv("USE_RAG", "true").lower() == "true"  # RAG ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: true)

# ë²¡í„° DB ì „ì—­ ë³€ìˆ˜
vector_store = None

# ì±•í„° ì½˜í…ì¸  ìºì‹œ (ë©”ëª¨ë¦¬ ê¸°ë°˜, DB ì—†ì´)
# í‚¤: (course_title, chapter_title, chapter_description) íŠœí”Œ
# ê°’: ChapterContent ê°ì²´
chapter_cache = {}


# ìš”ì²­ ëª¨ë¸
class StudyTopicRequest(BaseModel):
    topic: str
    difficulty: Optional[str] = "ì¤‘ê¸‰"
    max_chapters: Optional[int] = 3
    course_description: Optional[str] = None


class ChapterRequest(BaseModel):
    course_title: str
    course_description: str
    chapter_title: str
    chapter_description: str


# ì‘ë‹µ ëª¨ë¸
class ConceptResponse(BaseModel):
    title: str
    description: str
    contents: str


class ExerciseResponse(BaseModel):
    title: str
    description: str
    contents: str


class QuizItem(BaseModel):
    quiz: str


class QuizResponse(BaseModel):
    quizes: List[QuizItem]


class Chapter(BaseModel):
    chapterId: int
    chapterTitle: str
    chapterDescription: str


class Course(BaseModel):
    id: int
    chapters: List[Chapter]


class CourseResponse(BaseModel):
    course: Course


class ChapterContent(BaseModel):
    chapter: Chapter
    concept: ConceptResponse
    exercise: ExerciseResponse
    quiz: QuizResponse


class StudyMaterialResponse(BaseModel):
    course: Course
    chapters: List[ChapterContent]


class DownloadResponse(BaseModel):
    filename: str
    content: str


# RAG ë²¡í„° DB ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_rag_vector_db():
    """RAG ë²¡í„° DBë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global vector_store

    if not USE_RAG or not RAG_AVAILABLE:
        return None

    try:
        db_path = Path(VECTOR_DB_PATH)
        if not db_path.exists():
            logger.warning(f"ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
            logger.warning(
                "RAG ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. USE_RAG=falseë¡œ ì„¤ì •í•˜ê±°ë‚˜ ë²¡í„° DBë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
            )
            return None

        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ë²¡í„° DB ìƒì„± ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•¨)
        if VECTOR_DB_EMBEDDING_MODEL == "gemini":
            # GEMINI_API_KEYë¥¼ ì‚¬ìš© (GOOGLE_API_KEYë„ í™•ì¸)
            api_key = GEMINI_API_KEY or os.getenv("GOOGLE_API_KEY")
            if not api_key:
                logger.warning("GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            embeddings = GoogleGenerativeAIEmbeddings(
                model="models/text-embedding-004", google_api_key=api_key
            )
        elif VECTOR_DB_EMBEDDING_MODEL == "openai":
            if not OPENAI_EMBEDDINGS_AVAILABLE:
                logger.warning("langchain-openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return None

            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            # text-embedding-3-small ì‚¬ìš© (ìƒì„± ì‹œ ì‚¬ìš©í•œ ëª¨ë¸ê³¼ ë™ì¼)
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=api_key,
                max_retries=10,
            )
        else:
            logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© ëª¨ë¸: {VECTOR_DB_EMBEDDING_MODEL}")
            return None

        # ë²¡í„° DB ë¡œë“œ
        vector_store = FAISS.load_local(
            str(db_path), embeddings, allow_dangerous_deserialization=True
        )
        logger.info(f"RAG ë²¡í„° DB ë¡œë“œ ì™„ë£Œ: {db_path}")
        return vector_store

    except Exception as e:
        logger.error(f"ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.warning("RAG ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        return None


def search_rag_context(query: str, k: int = 3) -> str:
    """
    RAG ë²¡í„° DBì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

    Returns:
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬ë§·íŒ…í•œ ë¬¸ìì—´
    """
    global vector_store

    if not vector_store:
        return ""

    try:
        # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_store.similarity_search(query, k=k)

        if not docs:
            return ""

        # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context_parts = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get("file_name", "Unknown")
            content = doc.page_content[:500]  # ìµœëŒ€ 500ìë§Œ ì‚¬ìš©
            context_parts.append(f"[ì°¸ê³  ìë£Œ {i} - ì¶œì²˜: {source}]\n{content}")

        return "\n\n".join(context_parts)

    except Exception as e:
        logger.error(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return ""


# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë²¡í„° DB ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    if USE_RAG:
        initialize_rag_vector_db()


# JSON íŒŒì‹± í—¬í¼ í•¨ìˆ˜
def clean_json_response(raw: str) -> dict:
    """JSON ì‘ë‹µì—ì„œ ì½”ë“œë¸”ë¡ê³¼ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°"""
    cleaned = raw
    # ì½”ë“œë¸”ë¡ ì œê±°
    cleaned = cleaned.replace("```json", "").replace("```", "").strip()

    # JSON íŒŒì‹±
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        # ë¶ˆì™„ì „í•œ JSON ì²˜ë¦¬ ì‹œë„ (ì˜ë¦° ê²½ìš°)
        # ë¨¼ì € ì •ê·œì‹ìœ¼ë¡œ JSON ê°ì²´ ì¶”ì¶œ
        match = re.search(r"\{.*\}", cleaned, re.DOTALL)
        if match:
            json_str = match.group()
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                # ë¶ˆì™„ì „í•œ JSONì¸ ê²½ìš° - ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ í•­ëª© ì œê±° í›„ ì¬ì‹œë„
                # "quizes" ë°°ì—´ì´ ì˜ë¦° ê²½ìš° ì²˜ë¦¬
                if '"quizes"' in json_str:
                    # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ quiz í•­ëª© ì œê±°
                    # "quiz": "..." ë’¤ì— ë‹«íˆì§€ ì•Šì€ ë¶€ë¶„ ì°¾ê¸°
                    json_str = re.sub(
                        r',\s*"quiz":\s*"[^"]*$', "", json_str, flags=re.MULTILINE
                    )
                    json_str = re.sub(r",\s*\{[^}]*$", "", json_str, flags=re.MULTILINE)
                    # ë°°ì—´ê³¼ ê°ì²´ ë‹«ê¸°
                    if json_str.count("[") > json_str.count("]"):
                        json_str += "]"
                    if json_str.count("{") > json_str.count("}"):
                        json_str += "}"
                    try:
                        return json.loads(json_str)
                    except:
                        pass
        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:200]}")


def extract_contents_from_json(raw: str) -> dict:
    """ConceptMaker/ExerciseMaker ì‘ë‹µì—ì„œ contents ì¶”ì¶œ"""
    cleaned = raw.replace("```json", "").replace("```", "").strip()

    # title, description ì¶”ì¶œ
    title_match = re.search(r'"title"\s*:\s*"([^"]*)"', cleaned)
    description_match = re.search(r'"description"\s*:\s*"([^"]*)"', cleaned)

    title = title_match.group(1) if title_match else ""
    description = description_match.group(1) if description_match else ""

    # contents ì¶”ì¶œ (ë” ë³µì¡í•œ ì²˜ë¦¬)
    contents_part = cleaned.split('"contents"')[1] if '"contents"' in cleaned else ""
    if contents_part:
        contents_part = contents_part.strip()
        if contents_part.startswith(":"):
            contents_part = contents_part[1:].strip()
        if contents_part.startswith('"'):
            contents_part = contents_part[1:]

        # ë§ˆì§€ë§‰ ë”°ì˜´í‘œ ì°¾ê¸°
        last_quote = contents_part.rfind('"')
        if last_quote > 0:
            contents_part = contents_part[:last_quote]

        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ë³µì›
        contents = (
            contents_part.replace("\\n", "\n").replace("\\t", "\t").replace('\\"', '"')
        )
    else:
        contents = ""

    return {"title": title, "description": description, "contents": contents}


# ConceptMaker - ê°œë… ì •ë¦¬ ìƒì„±
async def generate_concept(request: ChapterRequest) -> ConceptResponse:
    logger.info(f"ê°œë… ì •ë¦¬ ìƒì„± ì‹œì‘: {request.chapter_title}")
    # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    search_query = f"{request.chapter_title} {request.chapter_description} ê°œë… ì„¤ëª…"
    rag_context = search_rag_context(search_query, k=3)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [
        f"Course Title: {request.course_title}",
        f"Course Description: {request.course_description}",
        f"Chapter Title: {request.chapter_title}",
        f"Chapter Description: {request.chapter_description}",
    ]

    # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if rag_context:
        prompt_parts.append(f"\n[ì°¸ê³  êµì¬ ìë£Œ]\n{rag_context}")

    prompt = "\n".join(prompt_parts)

    system_message = """ë‹¹ì‹ ì€ JSON ì‘ë‹µ ì „ìš© AIì…ë‹ˆë‹¤.

ì…ë ¥ ë°ì´í„°ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤:

	"courseTitle": "string",
	"courseDescription": "string",
	"chapterTitle": "string",
	"chapterDescription": "string"

ì‘ì—…:
You are an experienced educational content creator, skilled at transforming course details and specific prompts into comprehensive and well-structured self-study materials. Your goal is to generate 1000~1200 words worth of high-quality educational content in a markdown format that is easy for self-learners to understand. Use headings, subheadings, bullet points, etc. for easier understanding.
If reference materials are provided, use them to create accurate and comprehensive content that aligns with the reference materials.
output language: ko

ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON):
{
  "title": "string",
  "description": "string",
  "contents": "string"
}

âš ï¸ ê·œì¹™:
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ì ˆëŒ€ë¡œ {"output": {...}} ë˜ëŠ” ë¬¸ìì—´(JSON string) í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”.
- ëŒ€í™”í˜• ë©˜íŠ¸, ì„¤ëª…, ì‚¬ì¡± ì—†ì´ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- "contents" í•„ë“œëŠ” markdown ë¬¸ì„œ ë³¸ë¬¸ìœ¼ë¡œ ì±„ìš°ì„¸ìš” .
âš ï¸ ì¶œë ¥ ì‹œ ì ˆëŒ€ë¡œ Markdown ì½”ë“œë¸”ë¡(```json`, ``` ë“±)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
âš ï¸ ì ˆëŒ€ë¡œ {"output": {...}} í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ê³ , 
ì˜¤ì§ {"title": "...", "description": "...", "contents": "..."} êµ¬ì¡°ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    try:
        response = model.generate_content(
            f"{system_message}\n\n{prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=8192,
            ),
        )

        result = extract_contents_from_json(response.text)
        logger.info(f"ê°œë… ì •ë¦¬ ìƒì„± ì™„ë£Œ: {request.chapter_title}")
        return ConceptResponse(**result)
    except Exception as e:
        logger.error(f"ê°œë… ì •ë¦¬ ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {e}")
        raise HTTPException(status_code=500, detail=f"ê°œë… ì •ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# ExerciseMaker - ì‹¤ìŠµ ê³¼ì œ ìƒì„±
async def generate_exercise(request: ChapterRequest) -> ExerciseResponse:
    logger.info(f"ì‹¤ìŠµ ê³¼ì œ ìƒì„± ì‹œì‘: {request.chapter_title}")
    # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    search_query = f"{request.chapter_title} {request.chapter_description} ì‹¤ìŠµ ì—°ìŠµ"
    rag_context = search_rag_context(search_query, k=3)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [
        f"Course Title: {request.course_title}",
        f"course Description: {request.course_description}",
        f"Chapter Title: {request.chapter_title}",
        f"Chapter Description: {request.chapter_description}",
    ]

    # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if rag_context:
        prompt_parts.append(f"\n[ì°¸ê³  êµì¬ ìë£Œ]\n{rag_context}")

    prompt = "\n".join(prompt_parts)

    system_message = """ë‹¹ì‹ ì€ JSON ì‘ë‹µ ì „ìš© AIì…ë‹ˆë‹¤.

ì…ë ¥ ë°ì´í„°ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤:

	"courseTitle": "string",
	"courseDescription": "string",
	"chapterTitle": "string",
	"chapterDescription": "string"

ì‘ì—…:
You are an AI assistant specializing in education and personalized learning. Your task is to generate approximately three distinct, personalized self-study exercises. These exercises should focus on basic concepts relevant to the provided chapter ID, course title, course description, and the user's learning profile details. The output should be clearly structured, presenting each of the three exercises distinctly.
If reference materials are provided, use them to create exercises that align with the concepts covered in the reference materials.
# Step by Step instructions
1. Review the provided Chapter ID, Course Title, Course Description, and Prompt to understand the context and the learner's profile details.
2. Generate the first personalized self-study exercise, focusing on basic concepts relevant to the Chapter ID, Course Title, Course Description, and the chapter's description.
3. Generate the second personalized self-study exercise, ensuring it is distinct from the first and also focuses on basic concepts relevant to the Chapter ID, Course Title, Course Description, and the learner's profile details.
4. Generate the third personalized self-study exercise, ensuring it is distinct from the previous two and also focuses on basic concepts relevant to the Course Title, Course Description, Chapter title, and its description.
5. Review the three generated exercises. Are there approximately three distinct exercises? If not, go back to step 2 and adjust or regenerate the exercises as needed to meet the count and distinctness requirements.
6. Ensure each exercise is clearly structured and presented individually.
output language: ko


ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON):
{
  "title": "string",
  "description": "string",
  "contents": "string"
}

âš ï¸ ê·œì¹™:
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ì ˆëŒ€ë¡œ {"output": {...}} ë˜ëŠ” ë¬¸ìì—´(JSON string) í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”.
- ëŒ€í™”í˜• ë©˜íŠ¸, ì„¤ëª…, ì‚¬ì¡± ì—†ì´ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- "contents" í•„ë“œëŠ” markdown ë¬¸ì„œ ë³¸ë¬¸ìœ¼ë¡œ ì±„ìš°ì„¸ìš” .
âš ï¸ ì¶œë ¥ ì‹œ ì ˆëŒ€ë¡œ Markdown ì½”ë“œë¸”ë¡(```json`, ``` ë“±)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
âš ï¸ ì ˆëŒ€ë¡œ {"output": {...}} í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ê³ , 
ì˜¤ì§ {"title": "...", "description": "...", "contents": "..."} êµ¬ì¡°ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    try:
        response = model.generate_content(
            f"{system_message}\n\n{prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=8192,
            ),
        )

        result = extract_contents_from_json(response.text)
        logger.info(f"ì‹¤ìŠµ ê³¼ì œ ìƒì„± ì™„ë£Œ: {request.chapter_title}")
        return ExerciseResponse(**result)
    except Exception as e:
        logger.error(f"ì‹¤ìŠµ ê³¼ì œ ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {e}")
        raise HTTPException(status_code=500, detail=f"ì‹¤ìŠµ ê³¼ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# QuizMaker - í€´ì¦ˆ ìƒì„±
async def generate_quiz(
    request: ChapterRequest, course_prompt: str = ""
) -> QuizResponse:
    logger.info(f"í€´ì¦ˆ ìƒì„± ì‹œì‘: {request.chapter_title}")
    # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    search_query = f"{request.chapter_title} {request.chapter_description} í€´ì¦ˆ ë¬¸ì œ"
    rag_context = search_rag_context(search_query, k=3)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [
        f"Course Title: {request.course_title}",
        f"Chapter Title: {request.chapter_title}",
        f"Course Prompt: {course_prompt}",
    ]

    # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if rag_context:
        prompt_parts.append(f"\n[ì°¸ê³  êµì¬ ìë£Œ]\n{rag_context}")

    prompt = "\n".join(prompt_parts)

    system_message = """ë‹¹ì‹ ì€ JSON ì‘ë‹µ ì „ìš© AIì…ë‹ˆë‹¤.

ì…ë ¥ ë°ì´í„°ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤:

	"courseTitle": "string",
	"courseDescription": "string",
	"chapterTitle": "string",
	"chapterDescription": "string"

ì‘ì—…:
You are an expert quiz question generator, skilled at crafting subjective essay-type questions that provoke thoughtful responses. Your task is to generate three subjective essay-type quiz questions based on the provided course title, chapter title, and course prompt. The output must be a JSON array named `quizes`, containing three objects, each with a `quiz` (string) field.
If reference materials are provided, use them to create questions that test understanding of the key concepts covered in the reference materials.
# Step by Step instructions
1. Acknowledge the provided Course Title, Chapter Title, and Course Prompt.
2. Generate one subjective essay-type quiz question that is related to the Course Title, Chapter Title, and Course Prompt.
3. Review the question generated so far. If three questions have been generated, proceed to the next step. Otherwise, return to Step 2 and generate another question.
4. Format the three generated questions into a JSON array named `quizes`, where each question is an object with a `quiz` field.


ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON):
{
  "quizes" : [
    {
      "quiz" : "string"
    },
    {
      "quiz" : "string"
    },
    {
      "quiz" : "string"
  ]
}

âš ï¸ ê·œì¹™:
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ì ˆëŒ€ë¡œ {"output": {...}} ë˜ëŠ” ë¬¸ìì—´(JSON string) í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”.
- ëŒ€í™”í˜• ë©˜íŠ¸, ì„¤ëª…, ì‚¬ì¡± ì—†ì´ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- "contents" í•„ë“œëŠ” markdown ë¬¸ì„œ ë³¸ë¬¸ìœ¼ë¡œ ì±„ìš°ì„¸ìš” .
âš ï¸ ì¶œë ¥ ì‹œ ì ˆëŒ€ë¡œ Markdown ì½”ë“œë¸”ë¡(```json`, ``` ë“±)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
âš ï¸ ì ˆëŒ€ë¡œ {"output": {...}} í˜•íƒœë¡œ ê°ì‹¸ì§€ ë§ê³ , 
ì˜¤ì§ {"title": "...", "description": "...", "contents": "..."} êµ¬ì¡°ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    try:
        response = model.generate_content(
            f"{system_message}\n\n{prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=8192,  # í€´ì¦ˆ ì¦ê°€
            ),
        )

        # ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        try:
            response_text = response.text
        except ValueError as text_error:
            if "finish_reason" in str(text_error) or "Part" in str(text_error):
                logger.warning(f"ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨. ì¬ì‹œë„ ì¤‘: {request.chapter_title}")
                retry_prompt_parts = [
                    f"Course Title: {request.course_title}",
                    f"Chapter Title: {request.chapter_title}",
                    f"Course Prompt: {course_prompt}",
                    "",
                    "ìœ„ ì£¼ì œì— ëŒ€í•œ ì£¼ê´€ì‹ ì„œìˆ í˜• í€´ì¦ˆ ë¬¸ì œë¥¼ 3ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.",
                ]
                
                if rag_context:
                    retry_prompt_parts.append(f"\n[ì°¸ê³  êµì¬ ìë£Œ]\n{rag_context}")
                
                retry_prompt = "\n".join(retry_prompt_parts)

                response = model.generate_content(
                    f"{system_message}\n\n{retry_prompt}",
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.6,
                        max_output_tokens=8192,
                    ),
                )
                response_text = response.text
            else:
                raise

        result = clean_json_response(response_text)
        logger.info(f"í€´ì¦ˆ ìƒì„± ì™„ë£Œ: {request.chapter_title}")
        return QuizResponse(**result)
    except ValueError as e:
        if "finish_reason" in str(e) or "Part" in str(e):
            logger.error(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨ - {request.chapter_title}")
            raise Exception(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise
    except Exception as e:
        logger.error(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {type(e).__name__}: {e}", exc_info=True)
        raise Exception(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# CourseMaker - ê°•ì˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
async def generate_course(request: StudyTopicRequest) -> CourseResponse:
    course_description = request.course_description or request.topic

    # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹œì—ë„ ì°¸ê³ )
    search_query = f"{request.topic} {course_description} ì»¤ë¦¬í˜ëŸ¼"
    rag_context = search_rag_context(search_query, k=3)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [
        f"Title: {request.topic}",
        f"Description: {course_description}",
        f"Prompt: {request.topic}ì— ëŒ€í•œ ììŠµ ê³¼ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
        f"MaxChapters: {request.max_chapters}",
        f"Links:",
        f"Difficulty: {request.difficulty}",
    ]

    # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if rag_context:
        prompt_parts.append(f"\n[ì°¸ê³  êµì¬ ìë£Œ]\n{rag_context}")

    prompt = "\n".join(prompt_parts)

    system_message = """ë‹¹ì‹ ì€ JSON ì‘ë‹µ ì „ìš© AIì…ë‹ˆë‹¤.

ì…ë ¥ ë°ì´í„°ëŠ”:
{
	"courseTitle" : string // ì œëª©
	"courseDescription" : string // í•™ìŠµ ì£¼ì œ
	"prompt" : string // ë³¸ì¸ ì œì•½ ìƒí™©(í”„ë¡¬í”„íŠ¸)
	"maxchapters" : number // ìµœëŒ€ ì½”ìŠ¤ ê°œìˆ˜
	"link" : string[] // ê´€ë ¨ ë§í¬ 
	"difficulty": any // ë‚œì´ë„
}
í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆì–´.

ì‘ì—…:
You are an expert course designer and curriculum developer, skilled in creating comprehensive and tailored learning experiences. Your task is to generate a customized course syllabus in a structured JSON format. The syllabus should include a unique course ID and a list of chapters, where each chapter has its own ID, title, and description. You must use all provided course details, learner characteristics, maximum units, learning intensity, and any reference materials to create a comprehensive and tailored syllabus.
If reference materials are provided, use them to structure the course chapters in a logical learning progression that aligns with the content covered in the reference materials.
# Step by Step instructions
1. Create a unique Course ID (must be integer) for the syllabus.
2. Based on the courseTitle, courseDescription, prompts, maxchapters, and difficulty, generate the title and description for the first chapter.
3. based on link, get information from the URL provided and extract all contents from the page. Return the entire website contents if possible. If there is no URL in link, , do not return error and use Course Description to search the web and get contents from the promising search results.
3. Assign a unique ID to the chapter.
4. Check if the number of generated chapters has reached the Max Units. If not, go back to step 2 to generate the next chapter, ensuring progress towards the Max Units.




ì‘ë‹µ í˜•ì‹:
{
	"course": {
		"id": number;
		"chapters": [
			{
				"chapterId" : number
				"chapterTitle": string
				"chapterDescription" : string					
			},
			{
				...
			}
		]
	} 
}

ê·œì¹™:
You are working as part of an AI system, so no chit-chat and no explaining what you're doing and why.
DO NOT start with "Okay", or "Alright" or any preambles. Just the output, please."""

    try:
        response = model.generate_content(
            f"{system_message}\n\n{prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=4096,
            ),
        )

        result = clean_json_response(response.text)
        return CourseResponse(**result)
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"ê°•ì˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        )


# ë©”ì¸ API ì—”ë“œí¬ì¸íŠ¸
# --- Lazy Loadingì„ ìœ„í•œ ë¶„ë¦¬ëœ ì—”ë“œí¬ì¸íŠ¸ ---


@app.post("/generate-course", response_model=CourseResponse)
async def generate_course_only(request: StudyTopicRequest):
    """
    1ë‹¨ê³„: ì»¤ë¦¬í˜ëŸ¼(ëª©ì°¨)ë§Œ ë¨¼ì € ìƒì„±í•©ë‹ˆë‹¤. (ë¹ ë¦„)
    """
    try:
        return await generate_course(request)
    except Exception as e:
        logger.error(f"ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@app.post("/generate-chapter-content", response_model=ChapterContent)
async def generate_chapter_content_only(request: ChapterRequest):
    """
    2ë‹¨ê³„: íŠ¹ì • ì±•í„°ì˜ ìƒì„¸ ë‚´ìš©(ê°œë…, ì‹¤ìŠµ, í€´ì¦ˆ)ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì±•í„° í´ë¦­ ì‹œ í˜¸ì¶œ)
    ìºì‹œì— ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„± í›„ ìºì‹œì— ì €ì¥
    """
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = (
        request.course_title,
        request.chapter_title,
        request.chapter_description,
    )

    # ìºì‹œ í™•ì¸
    if cache_key in chapter_cache:
        logger.info(f"ìºì‹œì—ì„œ ë¡œë“œ: {request.chapter_title}")
        return chapter_cache[cache_key]

    logger.info(f"ì±•í„° ì½˜í…ì¸  ìƒì„± ì‹œì‘: {request.chapter_title}")
    try:
        # ë³‘ë ¬ë¡œ ìƒì„± (ê°œë…, ì‹¤ìŠµ, í€´ì¦ˆ) - ì—ëŸ¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
        results = await asyncio.gather(
            generate_concept(request),
            generate_exercise(request),
            generate_quiz(
                request, request.course_title
            ),  # course_titleì„ topicìœ¼ë¡œ ì‚¬ìš©
            return_exceptions=True,
        )

        # ê° ê²°ê³¼ í™•ì¸ ë° ì—ëŸ¬ ì²˜ë¦¬
        concept, exercise, quiz = results

        if isinstance(concept, Exception):
            logger.error(f"ê°œë… ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {concept}")
            raise HTTPException(
                status_code=500, detail=f"ê°œë… ì •ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(concept)}"
            )
        if isinstance(exercise, Exception):
            logger.error(f"ì‹¤ìŠµ ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {exercise}")
            raise HTTPException(
                status_code=500, detail=f"ì‹¤ìŠµ ê³¼ì œ ìƒì„± ì‹¤íŒ¨: {str(exercise)}"
            )
        if isinstance(quiz, Exception):
            logger.error(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {request.chapter_title} - {quiz}")
            raise HTTPException(status_code=500, detail=f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(quiz)}")

        logger.info(f"ì±•í„° ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {request.chapter_title}")

        # Chapter ê°ì²´ëŠ” ìš”ì²­ì—ì„œ ì¬êµ¬ì„± (ID ë“±ì€ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê´€ë¦¬í•œë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜, ì—¬ê¸°ì„œ ì„ì‹œë¡œ ìƒì„±)
        # ì—¬ê¸°ì„œëŠ” ì‘ë‹µ ëª¨ë¸ì„ ë§ì¶”ê¸° ìœ„í•´ ë”ë¯¸ Chapter ê°ì²´ë¥¼ ë§Œë“¤ê±°ë‚˜,
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ Chapter ì •ë³´ë¥¼ ë‹¤ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ Contentë§Œ ë¦¬í„´í•˜ëŠ”ê²Œ ì¢‹ì§€ë§Œ,
        # ê¸°ì¡´ ChapterContent êµ¬ì¡°ë¥¼ ì¬í™œìš©í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±

        # ì£¼ì˜: requestì—ëŠ” chapterIdê°€ ì—†ì„ ìˆ˜ ìˆìŒ.
        # í•˜ì§€ë§Œ ChapterContent ëª¨ë¸ì€ Chapter ê°ì²´ë¥¼ í¬í•¨í•´ì•¼ í•¨.
        # í¸ì˜ìƒ request ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Chapter ê°ì²´ ìƒì„±
        chapter_info = Chapter(
            chapterId=0,  # IDëŠ” í”„ë¡ íŠ¸ì—”ë“œ ì»¨í…ìŠ¤íŠ¸ì— ìˆìŒ
            chapterTitle=request.chapter_title,
            chapterDescription=request.chapter_description,
        )

        result = ChapterContent(
            chapter=chapter_info, concept=concept, exercise=exercise, quiz=quiz
        )

        # ìºì‹œì— ì €ì¥
        chapter_cache[cache_key] = result
        logger.debug(f"ìºì‹œì— ì €ì¥: {request.chapter_title}")

        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì±•í„° ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {request.chapter_title} - {type(e).__name__}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì±•í„° ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")


# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
@app.post("/generate-study-material", response_model=StudyMaterialResponse)
async def generate_study_material(request: StudyTopicRequest):
    """
    ê³µë¶€ ì£¼ì œë¥¼ ì…ë ¥ë°›ì•„ ììŠµ ê³¼ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì¼ê´„ ìƒì„± - ëŠë¦¼)
    """
    try:
        # 1. ê°•ì˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
        course_response = await generate_course(request)
        course = course_response.course

        # 2. ê° ì±•í„°ë³„ ì½˜í…ì¸  ìƒì„±
        chapters_content = []
        for chapter in course.chapters:
            chapter_request = ChapterRequest(
                course_title=request.topic,
                course_description=request.course_description or request.topic,
                chapter_title=chapter.chapterTitle,
                chapter_description=chapter.chapterDescription,
            )

            # ë³‘ë ¬ë¡œ ìƒì„± (ê°œë…, ì‹¤ìŠµ, í€´ì¦ˆ)
            # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°€ì§€ ìš”ì²­ì„ ë™ì‹œì— ë³´ëƒ„
            concept, exercise, quiz = await asyncio.gather(
                generate_concept(chapter_request),
                generate_exercise(chapter_request),
                generate_quiz(chapter_request, request.topic),
            )

            chapters_content.append(
                ChapterContent(
                    chapter=chapter, concept=concept, exercise=exercise, quiz=quiz
                )
            )

        return StudyMaterialResponse(course=course, chapters=chapters_content)
    except Exception as e:
        logger.error(f"ììŠµ ê³¼ì œ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ììŠµ ê³¼ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@app.get("/")
async def root():
    return {
        "message": "ììŠµ ê³¼ì œ ìƒì„± API",
        "version": "1.0.0",
        "endpoints": {
            "POST /generate-study-material": "ê³µë¶€ ì£¼ì œë¥¼ ì…ë ¥ë°›ì•„ ììŠµ ê³¼ì œ ìƒì„±"
        },
    }


@app.get("/health")
async def health():
    return {"status": "healthy"}


# ì±•í„° ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
@app.post("/download-chapter", response_model=DownloadResponse)
async def download_chapter(request: ChapterRequest):
    """
    ì±•í„° ì½˜í…ì¸ ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±
    cache_key = (
        request.course_title,
        request.chapter_title,
        request.chapter_description,
    )

    if cache_key in chapter_cache:
        content = chapter_cache[cache_key]
    else:
        # ì—†ìœ¼ë©´ ìƒì„± (generate_chapter_content_only ì¬ì‚¬ìš©)
        content = await generate_chapter_content_only(request)

    # Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    markdown = f"""# {content.chapter.chapterTitle}

{content.chapter.chapterDescription}

---

## ğŸ“š ê°œë… í•™ìŠµ

### {content.concept.title}

{content.concept.description}

{content.concept.contents}

---

## ğŸ’» ì‹¤ìŠµ ê³¼ì œ

### {content.exercise.title}

{content.exercise.description}

{content.exercise.contents}

---

## â“ í€´ì¦ˆ

"""

    for idx, quiz_item in enumerate(content.quiz.quizes, 1):
        markdown += f"### ë¬¸ì œ {idx}\n\n{quiz_item.quiz}\n\n---\n\n"

    # íŒŒì¼ëª… ìƒì„±: íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
    import re
    safe_filename = re.sub(r'[<>:"/\\|?*]', '', content.chapter.chapterTitle)
    safe_filename = safe_filename.replace(' ', '_')
    
    return DownloadResponse(
        filename=f"{safe_filename}.md",
        content=markdown
    )


# í€´ì¦ˆ ì±„ì  ì—”ë“œí¬ì¸íŠ¸
class QuizGradingRequest(BaseModel):
    question: str
    answer: str
    chapter_title: str
    chapter_description: str


@app.post("/grade-quiz")
async def grade_quiz(request: QuizGradingRequest):
    """
    í€´ì¦ˆ ë‹µì•ˆì„ AIë¡œ ì±„ì í•©ë‹ˆë‹¤.
    """
    prompt = f"""ë‹¤ìŒì€ í•™ìŠµ í€´ì¦ˆ ë¬¸ì œì™€ í•™ìƒì˜ ë‹µì•ˆì…ë‹ˆë‹¤.

**ë¬¸ì œ:**
{request.question}

**í•™ìƒ ë‹µì•ˆ:**
{request.answer}

**ì±•í„° ì •ë³´:**
- ì œëª©: {request.chapter_title}
- ì„¤ëª…: {request.chapter_description}

ìœ„ ë‹µì•ˆì„ ì±„ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
  "score": 0-100 ì‚¬ì´ì˜ ì ìˆ˜,
  "feedback": "ìƒì„¸í•œ í”¼ë“œë°± (í•œêµ­ì–´)",
  "correct_points": ["ë§ì€ ë¶€ë¶„ 1", "ë§ì€ ë¶€ë¶„ 2"],
  "improvements": ["ê°œì„ í•  ì  1", "ê°œì„ í•  ì  2"]
}}
"""

    system_message = """ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ë‹µì•ˆì„ ê³µì •í•˜ê³  ê±´ì„¤ì ìœ¼ë¡œ ì±„ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.
ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ë¡œ ì£¼ë˜, ë‹µì•ˆì˜ ì™„ì„±ë„, ì •í™•ì„±, ì´í•´ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ë°˜ë“œì‹œ ì™„ì „í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. JSONì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì™„ì „íˆ í¬í•¨í•˜ì„¸ìš”:
{
  "score": ìˆ«ì,
  "feedback": "ë¬¸ìì—´",
  "correct_points": ["ë¬¸ìì—´ ë°°ì—´"],
  "improvements": ["ë¬¸ìì—´ ë°°ì—´"]
}"""

    try:
        response = model.generate_content(
            f"{system_message}\n\n{prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,  # ì±„ì ì€ ì¼ê´€ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ë‚®ì€ temperature
                max_output_tokens=4096,  # ê¸´ í”¼ë“œë°±ì„ ìœ„í•´ ì¦ê°€
            ),
        )

        # ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        try:
            response_text = response.text
        except ValueError as text_error:
            if "finish_reason" in str(text_error) or "Part" in str(text_error):
                logger.warning("ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨. ì¬ì‹œë„ ì¤‘...")
                response = model.generate_content(
                    f"{system_message}\n\n{prompt}",
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.2,
                        max_output_tokens=4096,
                    ),
                )
                response_text = response.text
            else:
                raise

        result = clean_json_response(response_text)

        # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        if "correct_points" not in result:
            result["correct_points"] = []
        if "improvements" not in result:
            result["improvements"] = []
        if "score" not in result:
            result["score"] = 0
        if "feedback" not in result:
            result["feedback"] = "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return result
    except Exception as e:
        logger.error(f"í€´ì¦ˆ ì±„ì  ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í€´ì¦ˆ ì±„ì  ì‹¤íŒ¨: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001)
