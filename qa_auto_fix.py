"""
QA ë¡œê·¸ ìë™ ë¶„ì„ ë° ìˆ˜ì • ì œì•ˆ ì‹œìŠ¤í…œ

qa_logs/suggestions.md íŒŒì¼ì´ ìƒì„±ë˜ë©´ ìë™ìœ¼ë¡œ:
1. ì‹¤íŒ¨í•œ í¬ì¸íŠ¸ ë¶„ì„
2. ìˆ˜ì • patch diff ìƒì„±
3. ì‚¬ìš©ìì—ê²Œ ì ìš© ì—¬ë¶€ í™•ì¸

ì‚¬ìš©ë²•:
    python qa_auto_fix.py

ë˜ëŠ” íŒŒì¼ ê°ì‹œ ëª¨ë“œ:
    python qa_auto_fix.py --watch
"""
import os
import re
import json
import difflib
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent
QA_LOGS_DIR = PROJECT_ROOT / "qa_logs"
SUGGESTIONS_FILE = QA_LOGS_DIR / "suggestions.md"


def analyze_failures(suggestions_content: str) -> Dict[str, List[str]]:
    """
    suggestions.md íŒŒì¼ì—ì„œ ì‹¤íŒ¨í•œ í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        suggestions_content: suggestions.md íŒŒì¼ ë‚´ìš©
    
    Returns:
        Dict: ë¶„ì„ ê²°ê³¼
            - errors: ì—ëŸ¬ ëª©ë¡
            - warnings: ê²½ê³  ëª©ë¡
            - improvements: ê°œì„  ì‚¬í•­ ëª©ë¡
            - code_issues: ì½”ë“œ ë¬¸ì œ ëª©ë¡
    """
    analysis = {
        "errors": [],
        "warnings": [],
        "improvements": [],
        "code_issues": [],
        "test_failures": [],
        "performance_issues": []
    }
    
    lines = suggestions_content.split('\n')
    current_section = None
    
    for i, line in enumerate(lines):
        # ì„¹ì…˜ í—¤ë” ê°ì§€
        if line.startswith('#'):
            current_section = line.strip('#').strip().lower()
        
        # ì—ëŸ¬ íŒ¨í„´ ê°ì§€
        if any(keyword in line.lower() for keyword in ['error', 'fail', 'exception', 'crash']):
            analysis["errors"].append({
                "line": i + 1,
                "content": line.strip(),
                "context": '\n'.join(lines[max(0, i-2):min(len(lines), i+3)])
            })
        
        # ê²½ê³  íŒ¨í„´ ê°ì§€
        if any(keyword in line.lower() for keyword in ['warning', 'deprecated', 'should', 'consider']):
            analysis["warnings"].append({
                "line": i + 1,
                "content": line.strip(),
                "context": '\n'.join(lines[max(0, i-2):min(len(lines), i+3)])
            })
        
        # í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ê°ì§€
        if 'test' in line.lower() and ('fail' in line.lower() or 'âŒ' in line or 'âœ—' in line):
            analysis["test_failures"].append({
                "line": i + 1,
                "content": line.strip(),
                "context": '\n'.join(lines[max(0, i-2):min(len(lines), i+3)])
            })
        
        # ì„±ëŠ¥ ë¬¸ì œ ê°ì§€
        if any(keyword in line.lower() for keyword in ['slow', 'performance', 'timeout', 'memory']):
            analysis["performance_issues"].append({
                "line": i + 1,
                "content": line.strip(),
                "context": '\n'.join(lines[max(0, i-2):min(len(lines), i+3)])
            })
        
        # ì½”ë“œ ë¬¸ì œ ê°ì§€ (íŒŒì¼ ê²½ë¡œ í¬í•¨)
        file_pattern = r'([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))'
        if re.search(file_pattern, line) and any(keyword in line.lower() for keyword in ['fix', 'change', 'update', 'modify']):
            analysis["code_issues"].append({
                "line": i + 1,
                "content": line.strip(),
                "file": re.search(file_pattern, line).group(1) if re.search(file_pattern, line) else None
            })
    
    return analysis


def extract_file_paths(suggestions_content: str) -> List[str]:
    """
    suggestions.mdì—ì„œ ì–¸ê¸‰ëœ íŒŒì¼ ê²½ë¡œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        suggestions_content: suggestions.md íŒŒì¼ ë‚´ìš©
    
    Returns:
        List[str]: íŒŒì¼ ê²½ë¡œ ëª©ë¡
    """
    file_paths = []
    
    # ì¼ë°˜ì ì¸ íŒŒì¼ ê²½ë¡œ íŒ¨í„´
    patterns = [
        r'`([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))`',  # ë°±í‹±ìœ¼ë¡œ ê°ì‹¸ì§„ íŒŒì¼
        r'([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))',  # ì¼ë°˜ íŒŒì¼ ê²½ë¡œ
        r'File:\s*([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))',  # File: ì ‘ë‘ì‚¬
        r'Path:\s*([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))',  # Path: ì ‘ë‘ì‚¬
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, suggestions_content)
        for match in matches:
            file_path = match[0] if isinstance(match, tuple) else match
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œë¡œ ì •ê·œí™”
            if not file_path.startswith(('app/', 'frontend/', './', '../')):
                # ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ì‹œë„
                if os.path.exists(file_path):
                    file_paths.append(file_path)
                elif os.path.exists(f"app/{file_path}"):
                    file_paths.append(f"app/{file_path}")
                elif os.path.exists(f"frontend/src/{file_path}"):
                    file_paths.append(f"frontend/src/{file_path}")
            else:
                file_paths.append(file_path)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ê·œí™”
    unique_paths = []
    for path in set(file_paths):
        normalized = Path(path).as_posix()
        if (PROJECT_ROOT / normalized).exists():
            unique_paths.append(normalized)
    
    return unique_paths


def parse_suggestion_line(line: str) -> Optional[Dict]:
    """
    ì œì•ˆ ë¼ì¸ì„ íŒŒì‹±í•˜ì—¬ ìˆ˜ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        line: ì œì•ˆ ë¼ì¸ (ì˜ˆ: "app/main.py:123: ì—ëŸ¬ ë©”ì‹œì§€")
    
    Returns:
        Optional[Dict]: íŒŒì‹±ëœ ì •ë³´ ë˜ëŠ” None
    """
    # íŒŒì¼:ë¼ì¸:ì„¤ëª… í˜•ì‹
    pattern1 = r'([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md)):(\d+):\s*(.+)'
    match1 = re.match(pattern1, line)
    if match1:
        return {
            "file": match1.group(1),
            "line": int(match1.group(3)),
            "message": match1.group(4),
            "type": "line_specific"
        }
    
    # íŒŒì¼:ë¼ì¸ í˜•ì‹
    pattern2 = r'([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md)):(\d+)'
    match2 = re.match(pattern2, line)
    if match2:
        return {
            "file": match2.group(1),
            "line": int(match2.group(3)),
            "message": "",
            "type": "line_specific"
        }
    
    # íŒŒì¼ë§Œ ì–¸ê¸‰
    pattern3 = r'`([a-zA-Z0-9_/\\\.]+\.(py|tsx?|ts|jsx?|js|md))`'
    match3 = re.search(pattern3, line)
    if match3:
        return {
            "file": match3.group(1),
            "line": None,
            "message": line,
            "type": "file_general"
        }
    
    return None


def generate_patch(file_path: str, suggestions_content: str, analysis: Dict) -> Optional[str]:
    """
    ì œì•ˆ ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì • íŒ¨ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        file_path: ìˆ˜ì •í•  íŒŒì¼ ê²½ë¡œ
        suggestions_content: suggestions.md ë‚´ìš©
        analysis: ë¶„ì„ ê²°ê³¼
    
    Returns:
        Optional[str]: diff í˜•ì‹ì˜ íŒ¨ì¹˜, ìƒì„± ì‹¤íŒ¨ ì‹œ None
    
    ë³€ê²½ ì´ìœ :
        - ë” ì •êµí•œ íŒ¨ì¹˜ ìƒì„± ë¡œì§ êµ¬í˜„
        - ë¼ì¸ë³„ ìˆ˜ì • ì‚¬í•­ ì¶”ì¶œ
        - ì‹¤ì œ ì½”ë“œ ìˆ˜ì • ì œì•ˆ ìƒì„±
    """
    full_path = PROJECT_ROOT / file_path
    
    if not full_path.exists():
        return None
    
    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            original_lines = f.readlines()
        
        modified_lines = original_lines.copy()
        changes_made = False
        
        # íŒŒì¼ ê´€ë ¨ ì œì•ˆ ì‚¬í•­ ì°¾ê¸°
        file_suggestions = []
        lines = suggestions_content.split('\n')
        
        for i, line in enumerate(lines):
            parsed = parse_suggestion_line(line.strip())
            if parsed and (parsed["file"] == file_path or file_path.endswith(parsed["file"])):
                file_suggestions.append({
                    **parsed,
                    "source_line": i + 1,
                    "context": '\n'.join(lines[max(0, i-2):min(len(lines), i+3)])
                })
        
        # ë¼ì¸ë³„ ìˆ˜ì • ì ìš©
        for suggestion in file_suggestions:
            if suggestion["type"] == "line_specific" and suggestion["line"]:
                line_num = suggestion["line"] - 1  # 0-based index
                
                if 0 <= line_num < len(modified_lines):
                    original_line = modified_lines[line_num]
                    
                    # ì¼ë°˜ì ì¸ ìˆ˜ì • íŒ¨í„´ ì ìš©
                    message = suggestion["message"].lower()
                    
                    # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ ì œê±°
                    if "unused" in message or "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”" in message:
                        # ë³€ìˆ˜ëª… ì¶”ì¶œ ì‹œë„
                        var_match = re.search(r'(\w+)', message)
                        if var_match:
                            var_name = var_match.group(1)
                            # í•´ë‹¹ ë¼ì¸ì—ì„œ ë³€ìˆ˜ ì„ ì–¸ ì°¾ê¸°
                            if var_name in original_line and ('=' in original_line or ':' in original_line):
                                # ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì œê±° (ì•ˆì „ì„ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬)
                                modified_lines[line_num] = f"# {original_line.rstrip()}\n"
                                changes_made = True
                    
                    # import ì •ë¦¬
                    elif "import" in message and ("unused" in message or "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”" in message):
                        if original_line.strip().startswith("import") or original_line.strip().startswith("from"):
                            modified_lines[line_num] = f"# {original_line.rstrip()}\n"
                            changes_made = True
                    
                    # íƒ€ì… íŒíŠ¸ ì¶”ê°€
                    elif "type" in message and ("hint" in message or "annotation" in message):
                        # ê°„ë‹¨í•œ íƒ€ì… íŒíŠ¸ ì¶”ê°€ëŠ” ë³µì¡í•˜ë¯€ë¡œ ìŠ¤í‚µ
                        pass
                    
                    # ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
                    elif "error" in message or "exception" in message or "try" in message:
                        # try-except ë¸”ë¡ ì¶”ê°€ëŠ” ë³µì¡í•˜ë¯€ë¡œ ìŠ¤í‚µ
                        pass
        
        # diff ìƒì„±
        if changes_made:
            diff = difflib.unified_diff(
                original_lines,
                modified_lines,
                fromfile=f'a/{file_path}',
                tofile=f'b/{file_path}',
                lineterm='',
                n=3  # ì»¨í…ìŠ¤íŠ¸ 3ì¤„
            )
            return ''.join(diff)
        
        return None
        
    except Exception as e:
        print(f"Error generating patch for {file_path}: {e}")
        import traceback
        traceback.print_exc()
        return None


def process_suggestions_file() -> Tuple[Dict, List[Tuple[str, str]]]:
    """
    suggestions.md íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ë¶„ì„ ê²°ê³¼ì™€ íŒ¨ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        Tuple[Dict, List[Tuple[str, str]]]: (ë¶„ì„ ê²°ê³¼, [(íŒŒì¼ê²½ë¡œ, íŒ¨ì¹˜)] ë¦¬ìŠ¤íŠ¸)
    """
    if not SUGGESTIONS_FILE.exists():
        print(f"âŒ {SUGGESTIONS_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}, []
    
    print(f"ğŸ“„ {SUGGESTIONS_FILE} íŒŒì¼ì„ ë¶„ì„ ì¤‘...")
    
    with open(SUGGESTIONS_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ì‹¤íŒ¨ í¬ì¸íŠ¸ ë¶„ì„
    print("\nğŸ” ì‹¤íŒ¨í•œ í¬ì¸íŠ¸ ë¶„ì„ ì¤‘...")
    analysis = analyze_failures(content)
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    print("="*60)
    
    if analysis["errors"]:
        print(f"\nâŒ ì—ëŸ¬: {len(analysis['errors'])}ê°œ ë°œê²¬")
        for error in analysis["errors"][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            print(f"  - Line {error['line']}: {error['content'][:80]}")
    
    if analysis["warnings"]:
        print(f"\nâš ï¸  ê²½ê³ : {len(analysis['warnings'])}ê°œ ë°œê²¬")
        for warning in analysis["warnings"][:5]:
            print(f"  - Line {warning['line']}: {warning['content'][:80]}")
    
    if analysis["test_failures"]:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {len(analysis['test_failures'])}ê°œ ë°œê²¬")
        for failure in analysis["test_failures"][:5]:
            print(f"  - Line {failure['line']}: {failure['content'][:80]}")
    
    if analysis["code_issues"]:
        print(f"\nğŸ’» ì½”ë“œ ë¬¸ì œ: {len(analysis['code_issues'])}ê°œ ë°œê²¬")
        for issue in analysis["code_issues"][:5]:
            print(f"  - Line {issue['line']}: {issue['content'][:80]}")
    
    # íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
    print("\nğŸ“ ê´€ë ¨ íŒŒì¼ ì¶”ì¶œ ì¤‘...")
    file_paths = extract_file_paths(content)
    
    if file_paths:
        print(f"ë°œê²¬ëœ íŒŒì¼: {len(file_paths)}ê°œ")
        for path in file_paths[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            print(f"  - {path}")
    else:
        print("  ê´€ë ¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # íŒ¨ì¹˜ ìƒì„±
    print("\nğŸ”§ ìˆ˜ì • íŒ¨ì¹˜ ìƒì„± ì¤‘...")
    patches = []
    
    for file_path in file_paths[:5]:  # ìµœëŒ€ 5ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬
        patch = generate_patch(file_path, content, analysis)
        if patch:
            patches.append((file_path, patch))
            print(f"  âœ“ {file_path} íŒ¨ì¹˜ ìƒì„± ì™„ë£Œ")
    
    return analysis, patches


def apply_patch(file_path: str, patch: str) -> bool:
    """
    íŒ¨ì¹˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
        patch: diff í˜•ì‹ì˜ íŒ¨ì¹˜
    
    Returns:
        bool: ì ìš© ì„±ê³µ ì—¬ë¶€
    
    ë³€ê²½ ì´ìœ :
        - unified diff í˜•ì‹ íŒŒì‹± ê°œì„ 
        - ë°±ì—… íŒŒì¼ ìƒì„±
        - ì•ˆì „í•œ íŒ¨ì¹˜ ì ìš© (ê²€ì¦ í›„ ì ìš©)
    """
    full_path = PROJECT_ROOT / file_path
    
    if not full_path.exists():
        print(f"  âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # ë°±ì—… ìƒì„±
        backup_path = full_path.with_suffix(full_path.suffix + f'.backup.{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        with open(full_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
            original_lines = f.readlines()
        
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(original_content)
        
        print(f"  ğŸ’¾ ë°±ì—… ìƒì„±: {backup_path.name}")
        
        # unified diff íŒŒì‹±
        patch_lines = patch.splitlines()
        new_lines = original_lines.copy()
        
        i = 0
        while i < len(patch_lines):
            line = patch_lines[i]
            
            # hunk í—¤ë” ì°¾ê¸°: @@ -start,count +start,count @@
            if line.startswith('@@'):
                hunk_match = re.search(r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@', line)
                if hunk_match:
                    old_start = int(hunk_match.group(1)) - 1  # 0-based
                    old_count = int(hunk_match.group(2)) if hunk_match.group(2) else 1
                    new_start = int(hunk_match.group(3)) - 1
                    new_count = int(hunk_match.group(4)) if hunk_match.group(4) else 1
                    
                    i += 1
                    hunk_lines = []
                    
                    # hunk ë‚´ìš© ì½ê¸°
                    while i < len(patch_lines) and not patch_lines[i].startswith('@@'):
                        hunk_line = patch_lines[i]
                        if hunk_line.startswith('+') and not hunk_line.startswith('+++'):
                            # ì¶”ê°€í•  ë¼ì¸
                            hunk_lines.append(hunk_line[1:] + '\n')
                        elif hunk_line.startswith('-') and not hunk_line.startswith('---'):
                            # ì‚­ì œí•  ë¼ì¸ (ìŠ¤í‚µ)
                            pass
                        elif hunk_line.startswith(' '):
                            # ë³€ê²½ ì—†ìŒ (ìœ ì§€)
                            hunk_lines.append(hunk_line[1:] + '\n')
                        i += 1
                    
                    # ë¼ì¸ êµì²´
                    if 0 <= old_start < len(new_lines):
                        # ê¸°ì¡´ ë¼ì¸ ì œê±° ë° ìƒˆ ë¼ì¸ ì‚½ì…
                        new_lines = new_lines[:old_start] + hunk_lines + new_lines[old_start + old_count:]
            else:
                i += 1
        
        # ìˆ˜ì •ëœ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
        new_content = ''.join(new_lines)
        if new_content != original_content:
            # íŒŒì¼ì— ì ìš©
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            print(f"  âœ… íŒ¨ì¹˜ ì ìš© ì™„ë£Œ: {file_path}")
            print(f"     ë³€ê²½ëœ ë¼ì¸ ìˆ˜: ì•½ {abs(len(new_lines) - len(original_lines))}ì¤„")
            return True
        else:
            print(f"  âš ï¸  íŒ¨ì¹˜ ì ìš© í›„ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            # ë°±ì—… íŒŒì¼ ì‚­ì œ (ë³€ê²½ì‚¬í•­ ì—†ìŒ)
            backup_path.unlink()
            return False
        
    except Exception as e:
        print(f"  âŒ íŒ¨ì¹˜ ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='QA ë¡œê·¸ ìë™ ë¶„ì„ ë° ìˆ˜ì • ì œì•ˆ')
    parser.add_argument('--watch', action='store_true', help='íŒŒì¼ ê°ì‹œ ëª¨ë“œ')
    parser.add_argument('--auto-apply', action='store_true', help='ìë™ ì ìš© (ì£¼ì˜: ì‚¬ìš© ì „ ê²€í†  í•„ìš”)')
    args = parser.parse_args()
    
    if args.watch:
        print("ğŸ‘€ íŒŒì¼ ê°ì‹œ ëª¨ë“œ ì‹œì‘...")
        print(f"ê°ì‹œ ì¤‘: {SUGGESTIONS_FILE}")
        print("Ctrl+Cë¡œ ì¢…ë£Œ")
        
        last_modified = 0
        while True:
            try:
                if SUGGESTIONS_FILE.exists():
                    current_modified = SUGGESTIONS_FILE.stat().st_mtime
                    if current_modified > last_modified:
                        last_modified = current_modified
                        print(f"\nğŸ”„ íŒŒì¼ ë³€ê²½ ê°ì§€: {datetime.now()}")
                        analysis, patches = process_suggestions_file()
                        
                        if patches:
                            print("\n" + "="*60)
                            print("ğŸ“ ìƒì„±ëœ íŒ¨ì¹˜")
                            print("="*60)
                            
                            for file_path, patch in patches:
                                print(f"\n--- {file_path}")
                                print(patch[:500] + "..." if len(patch) > 500 else patch)
                            
                            if not args.auto_apply:
                                response = input("\nâ“ íŒ¨ì¹˜ë¥¼ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                                if response.lower() == 'y':
                                    for file_path, patch in patches:
                                        apply_patch(file_path, patch)
                                    print("âœ… íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
                                else:
                                    print("âŒ íŒ¨ì¹˜ ì ìš© ì·¨ì†Œ")
                            else:
                                print("âš ï¸  ìë™ ì ìš© ëª¨ë“œ: íŒ¨ì¹˜ê°€ ì ìš©ë©ë‹ˆë‹¤.")
                                for file_path, patch in patches:
                                    apply_patch(file_path, patch)
                
                import time
                time.sleep(2)  # 2ì´ˆë§ˆë‹¤ í™•ì¸
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ê°ì‹œ ëª¨ë“œ ì¢…ë£Œ")
                break
    else:
        # ì¼íšŒì„± ì‹¤í–‰
        analysis, patches = process_suggestions_file()
        
        if patches:
            print("\n" + "="*60)
            print("ğŸ“ ìƒì„±ëœ íŒ¨ì¹˜")
            print("="*60)
            
            for file_path, patch in patches:
                print(f"\n--- {file_path}")
                print(patch[:500] + "..." if len(patch) > 500 else patch)
            
            if not args.auto_apply:
                response = input("\nâ“ íŒ¨ì¹˜ë¥¼ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if response.lower() == 'y':
                    for file_path, patch in patches:
                        apply_patch(file_path, patch)
                    print("âœ… íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
                else:
                    print("âŒ íŒ¨ì¹˜ ì ìš© ì·¨ì†Œ")
            else:
                print("âš ï¸  ìë™ ì ìš© ëª¨ë“œ: íŒ¨ì¹˜ê°€ ì ìš©ë©ë‹ˆë‹¤.")
                for file_path, patch in patches:
                    apply_patch(file_path, patch)
        else:
            print("\nâœ… ìˆ˜ì •í•  íŒ¨ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

